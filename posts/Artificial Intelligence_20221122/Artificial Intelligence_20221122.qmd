---
title: "Artificial Intelligence 20221122"
author: "Siyun Min"
date: "2022-11-22"
categories: [SSU]
---
# 20221122

# 회귀 (regression)

학습 데이터에 부합되는 출력 값이 실수인 함수를 찾는 문제

$$
f^*(x) = arg~min_f~\sum_{i = 1}^{n}{(y_i - f(x_i))^2}
$$

![Untitled](./Untitled.png)

## 성능

오차 - 예측값과 실제값의 차이

- 테스트 데이터들에 대한 $(예측값 - 실제값)^2$의 평균 또는 평균의 제곱근

$$
E = \frac{1}{n}\sum_{i = 1}^{n}{(y_i - f(x_i))^2}
$$

- 모델의 종류(함수의 종류)에 영향을 받음

![Untitled](./Untitled%201.png)

## Overfitting (과적합)

지나치게 복잡한 모델(함수) 사용

### 대응방법

모델의 복잡도(model complexity)를 성능평가에 반영

$$
목적함수 = \text{오차의 합} + (가중치) \times (\text{모델 복잡도})
$$

모델 복잡도 - 벌점(penalty) 항

## Underfitting (부적합)

지나치게 단순한 모델(함수) 사용

![Untitled](./Untitled%202.png)

## 로지스틱 회귀 (logistic regression)

학습 데이터

$$
\{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}, y_i \in {0, 1}
$$

로지스틱 함수를 이용하여 함수 근사

$$
f(x) = \frac{1}{1 + e^{-\theta^T x}}
$$

![Untitled](./Untitled%203.png)

학습시 목적함수(출력이 Bernoulli Distribution을 따르는 경우)

$$
J(\theta) = -\frac{1}{N}\sum_{i = 1}{(y_i logf(x_i) + (1 - y_i) log(1 - f(x_i)))}
$$

경사하강법 사용 학습

# 비지도학습 (unsupervised learning)

결과정보가 없는 데이터들에 대해서 특정 패턴을 찾는 것

- 데이터에 잠재한 구조(structure), 계층구조(heirarchy)를 찾아내는 것
- 숨겨진 사용자 집단(hidden user group)을 찾는 것
- 문서들을 주제에 따라 구조화하는 것
- 로그(log) 정보를 사용하여 사용패턴(usage pattern)을 찾아내는 것

### 비지도 학습의 대상

군집화(clustering)

밀도추정(density estimation)

차원축소(dimensionality reduction)

![Untitled](./Untitled%204.png)

### 군집화 (clustering)

유사성에 따라 데이터를 분할하는 것

![Untitled](./Untitled%205.png)

일반 군집화 (hard clustering)

- 데이터는 하나의 군집에만 소속
    - ex) k-means 알고리즘

퍼지 군집화 (fuzzy clustering)

- 데이터가 여러 군집에 부분적으로 소속
- 소속정도의 합은 1이 됨
    - ex) 퍼지 k-means 알고리즘

용도

- 데이터에 내재된 구조 (underlying structure) 추정
- 데이터의 전반적 구조 통찰
- 가설 설정, 이상치 (anomaly, outlier) 감지
- 데이터 압축 - 동일 군집의 데이터를 같은 값으로 표현
- 데이터 전처리(preprocessing) 작업

성능

- 군집 내의 분산과 군집 간의 거리

## 밀도 추정 (density estimation)

부류(class) 별 데이터를 만들어 냈을 것으로 추정되는 확률분포를 찾는 것

![Untitled](./Untitled%206.png)

### 용도

각 부류 별로 주어진 데이터를 발생시키는 확률 계산

가장 확률이 높은 부류로 분류

### 모수적 (parametric) 밀도 추정

분포가 특정 수학적 함수의 형태를 가지고 있다고 가정

주어진 데이터를 가장 잘 반영하도록 함수의 파라미터 결정

전형적인 형태 - Gaussian (가우시안) 함수 또는 여러 개의 가우시안 함수의 혼합 (mixture of Gaussian)

### 비모수적 (nonparametric) 밀도 추정

분포에 대한 특정 함수를 가정하지 않고, 주어진 데이터를 사용하여 밀도함수의 형태 표현

전형적인 형태 - 히스토그램 (histogram)

## 차원축소 (dimension reduction)

고차원의 데이터를 정보의 손실을 최소화하면서 저차원으로 변환하는 것

### 목적

2, 3차원으로 변환해 시각화하면 직관적 데이터 분석 가능

차원의 저주 (curse of dimensionality) 문제 완화

### 차원의 저주 (curse of dimensionality)

차원이 커질수록 거리분포가 일정해지는 경향

![Untitled](./Untitled%207.png)

원이 증가함에 따라 부분공간의 개수가 기하급수적으로 증가

![Untitled](./Untitled%208.png)

### 주성분 분석 (principle component analysis, PCA)

분산이 큰 소수의 축들을 기준으로 데이터를 사상(projection)하여 저차원으로 변환

데이터의 공분산행렬(covariance matrix)에 대한 고유값 (eigenvalue)가 큰 소수의 고유벡터(eigenvector)를 사상 축으로 선택

![Untitled](./Untitled%209.png)